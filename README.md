# Home_Sales

In this project, knowledge of SparkSQL is used to determine key metrics about home sales data. Then Spark is used to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached.

## Tools used: 

   * PySpark SQL
   * Google colab Notebook

## The notebook provides answer to the following questions:

   * What is the average price for a four-bedroom house sold for each year? 
   * What is the average price of a home for each year the home was built, that has three bedrooms and three bathrooms? 
   * What is the average price of a home for each year the home was built, that has three bedrooms, three bathrooms, two floors, and is greater than or equal to 2,000 square feet? 
   * What is the average price of a home per "view" rating having an average home price greater than or equal to $350,000? Determine the run time for this query.

## Deliverables: 
   * Notebook file containing the code : Home_Sales.ipynb
